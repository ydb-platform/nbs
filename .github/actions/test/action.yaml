name: Run tests (ya make)
description: Run tests using ya make
inputs:
  test_target:
    required: false
    description: "test target"
  build_preset:
    required: true
    default: "relwithdebinfo"
    description: "relwithdebinfo, release-asan, release-tsan, release-msan, release-ubsan"
  test_size:
    required: false
    default: "small,medium,large"
    description: "small or small-medium or all"
  test_type:
    required: false
    default: "unittest,py3test,py2test,pytest"
    description: "run test type"
  test_threads:
    required: false
    default: "28"
    description: "Test threads count"
  link_threads:
    required: false
    default: "8"
    description: "link threads count"
  bazel_remote_uri:
    required: false
    description: "bazel-remote endpoint"
  bazel_remote_username:
    required: false
    description: "bazel-remote username"
  bazel_remote_password:
    required: false
    description: "bazel-remote password"
  cache_update:
    required: false
    description: "Use cache for tests"
  sync_to_s3:
    required: false
    default: "false"
    description: "Sync failed tests folders to s3"
  upload_ya_dir:
    required: false
    default: "no"
    description: "Upload ya dir to s3"
  clean_ya_dir:
    required: false
    default: "no"
    description: "Clean ya dir"
  use_network_cache:
    required: false
    default: "yes"
    description: "Use network cache"
  truncate_enabled:
    required: false
    default: "yes"
    description: "Truncate err files"
  number_of_retries:
    required: false
    default: "1"
    description: "Number of retries for ya make"

runs:
  using: composite
  steps:
    - name: Init
      shell: bash --noprofile --norc -eo pipefail -x {0}
      id: init
      run: |
        export TMP_DIR=/home/github/tmp
        {
          echo "TMP_DIR=$TMP_DIR"
          echo "LOG_DIR=$TMP_DIR/logs"
          echo "OUT_DIR=$TMP_DIR/out"
          echo "ARTIFACTS_DIR=$TMP_DIR/artifacts"
          echo "TESTS_DATA_DIR=$TMP_DIR/test_data"
          echo "REPORTS_ARTIFACTS_DIR=$TMP_DIR/artifacts/test_reports"
          echo "JUNIT_REPORT_XML=$TMP_DIR/junit.xml"
          echo "JUNIT_REPORT_PARTS=$TMP_DIR/junit-split"
          echo "SUMMARY_LINKS=$(mktemp -p /home/github)"
        } | tee -a $GITHUB_ENV

    - name: prepare
      shell: bash --noprofile --norc -eo pipefail -x {0}
      env:
        CLEAN_YA_DIR: ${{ inputs.clean_ya_dir }}
      run: |
        rm -rf $TMP_DIR $JUNIT_REPORT_XML $JUNIT_REPORT_PARTS $REPORTS_ARTIFACTS_DIR $TESTS_DATA_DIR
        mkdir -p $TMP_DIR $OUT_DIR $ARTIFACTS_DIR $LOG_DIR $JUNIT_REPORT_PARTS $REPORTS_ARTIFACTS_DIR $TESTS_DATA_DIR
        chown -R github:github $TMP_DIR $OUT_DIR $ARTIFACTS_DIR $LOG_DIR $JUNIT_REPORT_PARTS \
                               $REPORTS_ARTIFACTS_DIR $SUMMARY_LINKS $GITHUB_WORKSPACE \
                               $GITHUB_STEP_SUMMARY $TESTS_DATA_DIR
        # shellcheck disable=SC2193
        if [ "$CLEAN_YA_DIR" == "yes" ] && [ -d /home/github/.ya/ ]; then
          echo "Cleaning ya dir"
          rm -rf /home/github/.ya/
        fi
        # checking /etc/hosts to see if vm was created correctly
        cat /etc/hosts

    - name: Setup cache password file
      shell: bash --noprofile --norc -eo pipefail -x {0}
      env:
        BAZEL_REMOTE_PASSWORD: ${{ inputs.bazel_remote_password }}
      run: |
        export BAZEL_REMOTE_PASSWORD_FILE=$(mktemp)
        echo -n "$BAZEL_REMOTE_PASSWORD" > "$BAZEL_REMOTE_PASSWORD_FILE"
        echo "BAZEL_REMOTE_PASSWORD_FILE=$BAZEL_REMOTE_PASSWORD_FILE" >> "$GITHUB_ENV"
        chmod 600 "$BAZEL_REMOTE_PASSWORD_FILE"
        chown github:github "$BAZEL_REMOTE_PASSWORD_FILE"

    - name: ya test
      shell: bash --noprofile --norc -eo pipefail -x {0}
      env:
        NUMBER_OF_RETRIES: ${{ inputs.number_of_retries }}
        BUILD_PRESET: ${{ inputs.build_preset }}
        TEST_TARGET: ${{ inputs.test_target }}
        TEST_SIZE: ${{ inputs.test_size }}
        TEST_TYPE: ${{ inputs.test_type }}
        TEST_THREADS: ${{ inputs.test_threads }}
        LINK_THREADS: ${{ inputs.link_threads }}
        BAZEL_REMOTE_USERNAME: ${{ inputs.bazel_remote_username }}
        BAZEL_REMOTE_URI: ${{ inputs.bazel_remote_uri }}
        USE_NETWORK_CACHE: ${{ inputs.use_network_cache }}
        CACHE_UPDATE: ${{ inputs.cache_update }}
        TRUNCATE_ENABLED: ${{ inputs.truncate_enabled }}
        SYNC_TO_S3: ${{ inputs.sync_to_s3 || 'false' }}
        GITHUB_TOKEN: ${{ github.token }}
      run: |
        extra_params=(
          --run-all-tests
          --keep-going
          --retest
          --test-threads "$TEST_THREADS"
          --link-threads "$LINK_THREADS"
          --cache-size 512G
          --do-not-output-stderrs
          -T
          --nice 0
          --stat
          --output "$OUT_DIR"
          -DGITHUB_CI=yes
        )

        case "$BUILD_PRESET" in
          debug)
            extra_params+=(--build "debug")
            ;;
          relwithdebinfo)
            extra_params+=(--build "relwithdebinfo")
            ;;
          release-asan)
            extra_params+=(--build "release")
            extra_params+=(--sanitize="address")
            extra_params+=(-DSKIP_JUNK -DUSE_EAT_MY_DATA -DDEBUGINFO_LINES_ONLY)
            ;;
          release-tsan)
            extra_params+=(--build "release")
            extra_params+=(--sanitize="thread")
            extra_params+=(-DSKIP_JUNK -DUSE_EAT_MY_DATA -DDEBUGINFO_LINES_ONLY)
            ;;
          release-msan)
            extra_params+=(--build "release")
            extra_params+=(--sanitize="memory")
            extra_params+=(-DSKIP_JUNK -DUSE_EAT_MY_DATA -DDEBUGINFO_LINES_ONLY)
            ;;
          release-ubsan)
            extra_params+=(--build "release")
            extra_params+=(--sanitize="undefined")
            extra_params+=(-DSKIP_JUNK -DUSE_EAT_MY_DATA -DDEBUGINFO_LINES_ONLY)
            ;;
          *)
            echo "Invalid preset: $BUILD_PRESET"
            exit 1
            ;;
        esac

        # strip quotes from the string
        # TODO: remove it when pr.yaml gets updated
        TEST_TARGET=${TEST_TARGET//\"/}

        if [ -n "$TEST_TARGET" ]; then
          readarray -d ',' -t targets < <(printf "%s" "$TEST_TARGET")
          for target in "${targets[@]}"; do
            extra_params+=(--target="${target}")
          done
        fi

        if [ "$USE_NETWORK_CACHE" == "yes" ]; then
          if [ -n "$BAZEL_REMOTE_URI" ]; then
            extra_params+=(--bazel-remote-store)
            extra_params+=(--bazel-remote-base-uri "$BAZEL_REMOTE_URI")
          fi

          if [ -n "$BAZEL_REMOTE_USERNAME" ]; then
            extra_params+=(--bazel-remote-username "$BAZEL_REMOTE_USERNAME")
            extra_params+=(--bazel-remote-password-file "$BAZEL_REMOTE_PASSWORD_FILE")
          fi

          if [ "$CACHE_UPDATE" = "true" ]; then
            extra_params+=(--bazel-remote-put)
          fi
        fi

        # shellcheck disable=SC2153
        readarray -d ',' -t test_size < <(printf "%s" "$TEST_SIZE")
        # shellcheck disable=SC2153
        readarray -d ',' -t test_type < <(printf "%s" "$TEST_TYPE")

        date
        ./ya --version
        RETRIES="${NUMBER_OF_RETRIES}"
        OOM_CAN_BE_RETRIED=1
        BUILD_FAILED=0

        echo "RETRIES=${RETRIES}" | tee -a "$GITHUB_ENV"
        RETRY_FLAG=""
        i=0
        while [ "$RETRIES" -gt 0 ]; do
          RETRIES=$((RETRIES - 1))
          i=$((i + 1))
          RETRY_LOG_DIR="$LOG_DIR/$i"
          sudo -E -H -u github mkdir -p "$RETRY_LOG_DIR"
          echo "::group::ya-make-test-${i}"
          set +e
          (
            sudo -E -H -u github ./ya make "${test_size[@]/#/--test-size=}" \
                "${test_type[@]/#/--test-type=}" \
                "${extra_params[@]}" \
                --junit "${JUNIT_REPORT_XML}.${i}" \
                --log-file "$RETRY_LOG_DIR/ya_log.txt" \
                --evlog-file "$RETRY_LOG_DIR/ya_evlog.jsonl" \
                "$RETRY_FLAG";
            echo $? > exit_code
          ) |& tee "$RETRY_LOG_DIR/ya_make_output.txt"
          set -e
          RC=$(< exit_code)
          DO_RETRY=0
          case $RC in
            0)
              echo "ya test successfully finished, no errors"
              ls -la "${JUNIT_REPORT_XML}.${i}" || true
              date
              if [ -s "${JUNIT_REPORT_XML}.${i}" ]; then
                echo "${JUNIT_REPORT_XML}.${i} exists"
              else
                echo "${JUNIT_REPORT_XML}.${i} doesn't exist or has zero size"
              fi
              ;;
            137)
              echo "ya test returned $RC it was killed by OOM killer"
              if [ $OOM_CAN_BE_RETRIED -eq 0 ]; then
                DO_RETRY=0
              else
                DO_RETRY=1
                OOM_CAN_BE_RETRIED=0
                RETRIES=$((RETRIES + 1 ))
                echo "RETRIES=$((RETRIES + 1 ))" | tee -a "$GITHUB_ENV"
                echo "Retrying once because OOM killer killed ya-bin, increasing retry count by 1"
              fi
              ;;
            *)
              echo "ya test returned $RC"
              ls -la "${JUNIT_REPORT_XML}.${i}" || true
              date
              if [ -s "${JUNIT_REPORT_XML}.${i}" ]; then
                echo "${JUNIT_REPORT_XML}.${i} exists"
              else
                echo "${JUNIT_REPORT_XML}.${i} doesn't exist or has zero size"
              fi
              # disabling retries here for now until we will be able to
              # process junit with retried runs
              DO_RETRY=1
              RETRY_FLAG="-X"
              ;;
          esac

          echo "::group::s3-sync-logs"
          if [ "$SYNC_TO_S3" = "true" ];
          then
            sudo -E -H -u github s3cmd sync --follow-symlinks --acl-private --no-progress --stats --no-check-md5 "$RETRY_LOG_DIR/" "$S3_BUCKET_PATH/test_logs/${i}/"
          fi
          echo "::endgroup::"

          NEED_COPYING=0

          # shellcheck disable=SC2024
          if [ -f "${JUNIT_REPORT_XML}.${i}" ];
          then
            echo "::group::muted-tests"
            cat .github/config/muted_ya.txt
            MUTED_CONFIG=".github/config/muted_ya.txt"
            echo "::endgroup::"
            echo "::group::postprocess-junit-${i}"
            sudo -E -H -u github gzip -c "${JUNIT_REPORT_XML}.${i}" > "$REPORTS_ARTIFACTS_DIR/orig_junit.${i}.xml.gz"
            sudo -E -H -u github .github/scripts/tests/transform-ya-junit.py -i \
              -m "${MUTED_CONFIG}" \
              --ya-out "$OUT_DIR" \
              --log-url-prefix "$S3_WEBSITE_PREFIX/logs/${i}/" \
              --data-url-prefix "$S3_WEBSITE_PREFIX/test_data/${i}$GITHUB_WORKSPACE" \
              --log-out-dir "$ARTIFACTS_DIR/logs/${i}" \
              "${JUNIT_REPORT_XML}.${i}"

            sudo -E -H -u github .github/scripts/tests/split-junit.py -o "$JUNIT_REPORT_PARTS/${i}" "${JUNIT_REPORT_XML}.${i}"
            echo "::endgroup::"
            # exports BUILD_FAILED_COUNT if it is not zero, we need to save current value to compare it to new one in retries and if it is bigger - update it
            if [ -z "$BUILD_FAILED_COUNT" ]; then
              BUILD_FAILED_COUNT=0
            fi
            BUILD_FAILED_COUNT_TMP=$BUILD_FAILED_COUNT
            set +e
            (sudo -E -H -u github .github/scripts/tests/fail-checker.py "${JUNIT_REPORT_XML}.${i}"; echo $? > fail_checker_exit_code) |& tee fail-checker-output.log
            set -e
            if [ "$BUILD_FAILED_COUNT" -gt "$BUILD_FAILED_COUNT_TMP" ]; then
              echo "BUILD_FAILED_COUNT=$BUILD_FAILED_COUNT" | tee -a "$GITHUB_ENV"
            else
              echo "BUILD_FAILED_COUNT=$BUILD_FAILED_COUNT_TMP" | tee -a "$GITHUB_ENV"
              BUILD_FAILED_COUNT=$BUILD_FAILED_COUNT_TMP
            fi
            FAIL_CHECKER_RC=$(< fail_checker_exit_code)
            if [ "$FAIL_CHECKER_RC" -ne 0 ]; then
              NEED_COPYING=1
              echo "::group::Copy-failed-tests-data"
              sudo -E -H -u github .github/scripts/tests/fail-checker.py "${JUNIT_REPORT_XML}.${i}" --paths-only | while read -r path; do
                echo $path
                find "${GITHUB_WORKSPACE}/${path}" -print0 | xargs -0 cp -L -r --parents -t "$TESTS_DATA_DIR"
              done
              echo "::endgroup::"
            fi
            if [ "$FAIL_CHECKER_RC" -eq 237 ]; then
              BUILD_FAILED=1
            fi
          fi
          if [ "$NEED_COPYING" -ne "0" ];
          then
            chown -R github:github "$TESTS_DATA_DIR"
            echo "::group::remove-binaries-from-tests-data-dir"
            find "$TESTS_DATA_DIR" -type f -print0 | while IFS= read -r -d '' file; do
              if file --mime-type "$file" | grep -q 'application/x-executable'; then
                echo "$file"
                rm -f "$file"
              fi
            done
            echo "::endgroup::"
            echo "::group::remove-images-from-tests-data-dir"
            find "$TESTS_DATA_DIR" -name generated_raw_image -o -name generated_vmdk_image -o -name invalid_qcow2_image -o -name qcow2_fuzzing_image -o -name 'NVMENBS0*' -o -name generated_other_big_raw_image
            find "$TESTS_DATA_DIR" \( -name generated_raw_image -o -name generated_vmdk_image -o -name invalid_qcow2_image -o -name qcow2_fuzzing_image -o -name 'NVMENBS0*' -o -name generated_other_big_raw_image \) -delete
            echo "::endgroup::"
            echo "::group::truncate-err-files"
            find "$TESTS_DATA_DIR" -type f -name '*.err' -o -name '*.log' -o -name '*.out' -size +1G -print0 | while IFS= read -r -d '' file; do
                orig_size=$(du -h "$file" | cut -f1)
                echo "$file - $orig_size"
                # shellcheck disable=SC2193
                if [ "$TRUNCATE_ENABLED" == "yes" ]; then
                  truncate -s 1G "$file"
                  echo "... truncated (original size was $orig_size) ..." >> "$file"
                else
                  echo "not truncated"
                fi
            done
            echo "::endgroup::"
            echo "::group::s3-sync-test-data"
            if [ "$SYNC_TO_S3" = "true" ];
            then
              du -h "$TESTS_DATA_DIR/"
              sudo -E -H -u github s3cmd sync --follow-symlinks --acl-private --no-progress --stats --no-check-md5 "$TESTS_DATA_DIR/" "$S3_BUCKET_PATH/test_data/${i}/"
            fi
            echo "::endgroup::"
          fi
          # shellcheck disable=SC2024
          sudo -E -H -u github gzip -c "${JUNIT_REPORT_XML}.${i}" > "$REPORTS_ARTIFACTS_DIR/transformed_junit.${i}.xml.gz"
          sudo -E -H -u github tar -C "$JUNIT_REPORT_PARTS/.." -czf "${REPORTS_ARTIFACTS_DIR}/junit_parts.${i}.xml.tar.gz" "$(basename $JUNIT_REPORT_PARTS)/${i}" "${JUNIT_REPORT_XML}.${i}"*


          echo "::group::write-summary-${i}"
          sudo -E -H -u github mkdir -p $ARTIFACTS_DIR/summary/${i}

          cat $SUMMARY_LINKS | python3 -c 'import sys; print(" | ".join([v for _, v in sorted([l.strip().split(" ", 1) for l in sys.stdin], key=lambda a: (int(a[0]), a))]))' >> $GITHUB_STEP_SUMMARY

          platform_name=$(uname | tr '[:upper:]' '[:lower:]')-$(arch)

          export SUMMARY_OUT_ENV_PATH=$(mktemp -p /home/github)
          chown github:github $SUMMARY_OUT_ENV_PATH
          sudo -E -H -u github .github/scripts/tests/generate-summary.py \
            --summary-out-path "$ARTIFACTS_DIR/summary/${i}/" \
            --summary-out-env-path "$SUMMARY_OUT_ENV_PATH" \
            --summary-url-prefix "$S3_WEBSITE_PREFIX/summary/${i}/" \
            --build-preset "${platform_name}-${BUILD_PRESET}" \
            "Tests" ya-test.html "${JUNIT_REPORT_XML}.${i}"

          cat $SUMMARY_OUT_ENV_PATH | tee -a $GITHUB_STEP_SUMMARY
          echo "::endgroup::"

          if [ -d "$ARTIFACTS_DIR/logs/" ]; then
            echo "::group::cleaning-artifacts-log-dir"
            find "$ARTIFACTS_DIR/logs/" -type f -print0 | while IFS= read -r -d '' file; do
              if file --mime-type "$file" | grep -q 'application/x-executable'; then
                echo "$file"
                rm -f "$file"
              fi
            done
            echo "::endgroup::"
          fi

          echo "::group::s3-sync"
          sudo -E -H -u github s3cmd sync --follow-symlinks --acl-public --no-progress --stats --no-check-md5 "$ARTIFACTS_DIR/" "$S3_BUCKET_PATH/"
          echo "::endgroup::"

          if [ $DO_RETRY -eq 1 ]; then
            echo "Retrying..."
            echo "::endgroup::"
            continue
          else
            echo "::endgroup::"
            break
          fi
        done
        echo "exiting with code $FAIL_CHECKER_RC"
        echo "END_EXIT_CODE=${FAIL_CHECKER_RC}" |tee -a "$GITHUB_ENV"
        if [ "$BUILD_FAILED" -eq 1 ]; then
          echo "BUILD_FAILED=1" | tee -a "$GITHUB_ENV"
        else
          echo "BUILD_FAILED=0" | tee -a "$GITHUB_ENV"
        fi

    - name: copying system files
      if: ${{ !cancelled() }}
      shell: bash --noprofile --norc -eo pipefail -x {0}
      run: |
        sudo cp /var/log/kern.log "$LOG_DIR/kern.log" || true
        sudo chown -R github:github "$LOG_DIR/kern.log" || true

    - name: dump VM artifacts
      shell: bash --noprofile --norc -eo pipefail -x {0}
      if: ${{ !cancelled() }}
      run: |
        echo "::group::dump-vm-artifacts"
        sudo mkdir -p "$LOG_DIR/system_logs"
        # shellcheck disable=SC2024
        sudo dmesg -T > "$LOG_DIR/system_logs/dmesg.log" || true
        sudo cp /var/log/atop/atop_* "$LOG_DIR/system_logs/" || true
        sudo cp /var/log/syslog "$LOG_DIR/system_logs/syslog.log" || true
        sudo chown -R github:github "$LOG_DIR/system_logs/" || true
        sudo -E -H -u github s3cmd sync --follow-symlinks --acl-private --no-progress --stats --no-check-md5 "$LOG_DIR/system_logs/" "$S3_BUCKET_PATH/test_logs/"
        echo "::endgroup::"

    - name: Finish with END_EXIT_CODE
      shell: bash --noprofile --norc -eo pipefail -x {0}
      run: |
        echo "Tests ended with exit code $END_EXIT_CODE"
        if [ "$BUILD_FAILED" -eq 1 ]; then
          echo "Build failed, setting END_EXIT_CODE to 237"
          END_EXIT_CODE=237
        fi
        exit $END_EXIT_CODE

    - name: Sync test results to S3
      if: always()
      shell: bash --noprofile --norc -eo pipefail -x {0}
      run: |
        echo "::group::s3-sync"
        sudo -E -H -u github s3cmd sync --follow-symlinks --acl-public --no-progress --stats --no-check-md5 "$ARTIFACTS_DIR/" "$S3_BUCKET_PATH/"
        echo "::endgroup::"

    - name: Display links to s3 summary
      if: always()
      shell: bash --noprofile --norc -eo pipefail -x {0}
      run: |
        echo "::group::s3-report-links"
        echo ${S3_URL_PREFIX}/summary/ya-test.html
        echo ${S3_WEBSITE_PREFIX}/summary/ya-test.html
        echo "::endgroup::"

    - name: upload ya dir to s3 on success
      id: upload_ya_dir
      shell: bash --noprofile --norc -eo pipefail -x {0}
      if: success() && inputs.upload_ya_dir == 'yes'
      run: |
        function grep_ya_tc() {
          # shellcheck disable=SC2009
          ps aux | grep "[y]a-tc" || true
        }
        process_name="ya-tc"
        # by default ya-tc should terminate within 5 minutes
        timeout=360
        start_time=$(date +%s)
        while true; do
            if pgrep -x "$process_name"; then
                echo "$process_name is still running."
                grep_ya_tc
            else
                echo "$process_name is not running."
                grep_ya_tc
                break
            fi

            current_time=$(date +%s)
            elapsed_time=$((current_time - start_time))

            if [ "$elapsed_time" -ge "$timeout" ]; then
                echo "Timeout reached. $process_name is still running. killing it"
                grep_ya_tc
                pkill -f $process_name || true
                grep_ya_tc
                break
            fi

            sleep 5
        done

        # shellcheck disable=SC2009
        ps aux | grep ya
        # checking if files are not corrupted
        echo "::group::ya-files-empty"
        find /home/github/.ya/tools/ -type f -exec file {} \; | grep empty
        echo "::endgroup::"
        ya_bin_path=$(find /home/github/.ya/tools/ -type f -name "ya-bin")
        if [ ! -s "$ya_bin_path" ]; then
          echo "ya-bin exists but is empty"
          echo "empty_ya_bin=yes" >> $GITHUB_OUTPUT
        else
          echo "empty_ya_bin=no" >> $GITHUB_OUTPUT
          echo "::group::upload-ya-dir"

          df -h
          EXTENSION=tar.xz
          if [ "$EXTENSION" = "tar.zst" ] || [ "$EXTENSION" = "tar.zstd" ]; then COMPRESS_ARGS='zstd -16 -T60'; fi
          if [ "$EXTENSION" = "tar.xz" ]; then COMPRESS_ARGS='pixz -1'; fi
          if [ "$EXTENSION" = "tar.bz2" ]; then COMPRESS_ARGS=pbzip2; fi
          if [ "$EXTENSION" = "tar.gz" ]; then COMPRESS_ARGS=pigz; fi
          sudo -E -H -u github time tar -S -C /home/github -I "$COMPRESS_ARGS" -c -f  /home/github/tmp/ya.${EXTENSION} /home/github/.ya
          ls -lsha /home/github/tmp/ya.${EXTENSION}
          sudo -E -H -u github time aws s3 cp --no-progress  /home/github/tmp/ya.${EXTENSION} "$S3_BUCKET_PATH/ya_archive/ya.${EXTENSION}"
          echo "${S3_WEBSITE_PREFIX}/ya_archive/ya.${EXTENSION}" > /home/github/ya_web_url.txt
          echo "${S3_BUCKET_PATH}/ya_archive/ya.${EXTENSION}" > /home/github/ya_s3_url.txt
          df -h
          echo "::endgroup::"
        fi

    - name: upload ya url to s3 on success
      if: success() && inputs.upload_ya_dir == 'yes' && steps.upload_ya_dir.outputs.empty_ya_bin != 'yes'
      uses: actions/upload-artifact@v4
      with:
        name: ya_web_url_file
        path: /home/github/ya_web_url.txt
    - name: upload ya url to s3 on success
      if: success() && inputs.upload_ya_dir == 'yes' && steps.upload_ya_dir.outputs.empty_ya_bin != 'yes'
      uses: actions/upload-artifact@v4
      with:
        name: ya_s3_url_file
        path: /home/github/ya_s3_url.txt
    - name: Create directory listing on s3
      if: always()
      shell: bash --noprofile --norc -eo pipefail -x {0}
      run: |
        echo "::group::generate-listing"
        sudo -E -H -u github python3 .github/scripts/index.py "$S3_BUCKET_PATH" --generate-indexes --apply
        echo "::endgroup::"
    - name: show free space
      if: always()
      shell: bash --noprofile --norc -eo pipefail -x {0}
      run: df -h
