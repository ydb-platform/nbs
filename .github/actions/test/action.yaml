name: Run tests (ya make)
description: Run tests using ya make
inputs:
  test_target:
    required: false
    description: "test target"
  build_preset:
    required: true
    default: "relwithdebinfo"
    description: "relwithdebinfo, release-asan, release-tsan, release-msan, release-ubsan"
  test_size:
    required: false
    default: "small,medium,large"
    description: "small or small-medium or all"
  test_type:
    required: false
    default: "unittest,py3test,py2test,pytest"
    description: "run test type"
  test_threads:
    required: false
    default: "28"
    description: "Test threads count"
  link_threads:
    required: false
    default: "8"
    description: "link threads count"
  bazel_remote_uri:
    required: false
    description: "bazel-remote endpoint"
  bazel_remote_username:
    required: false
    description: "bazel-remote username"
  bazel_remote_password:
    required: false
    description: "bazel-remote password"
  cache_update:
    required: false
    description: "Use cache for tests"
  sync_to_s3:
    required: false
    default: 'false'
    description: 'Sync failed tests folders to s3'
  upload_ya_dir:
    required: false
    default: 'no'
    description: 'Upload ya dir to s3'
  clean_ya_dir:
    required: false
    default: 'no'
    description: 'Clean ya dir'
  use_network_cache:
    required: false
    default: 'yes'
    description: 'Use network cache'
  nebius:
    required: false
    default: 'no'
    description: 'Use nebius'
  truncate_enabled:
    required: false
    default: 'yes'
    description: 'Truncate err files'

runs:
  using: composite
  steps:
    - name: Init
      shell: bash --noprofile --norc -eo pipefail -x {0}
      id: init
      run: |
        export TMP_DIR=/home/github/tmp
        {
          echo "TMP_DIR=$TMP_DIR"
          echo "LOG_DIR=$TMP_DIR/logs"
          echo "OUT_DIR=$TMP_DIR/out"
          echo "ARTIFACTS_DIR=$TMP_DIR/artifacts"
          echo "TESTS_DATA_DIR=$TMP_DIR/test_data"
          echo "REPORTS_ARTIFACTS_DIR=$TMP_DIR/artifacts/test_reports"
          echo "JUNIT_REPORT_XML=$TMP_DIR/junit.xml"
          echo "JUNIT_REPORT_PARTS=$TMP_DIR/junit-split"
          echo "SUMMARY_LINKS=$(mktemp -p /home/github)"
        } >> $GITHUB_ENV

    - name: prepare
      shell: bash --noprofile --norc -eo pipefail -x {0}
      run: |
        rm -rf $TMP_DIR $JUNIT_REPORT_XML $JUNIT_REPORT_PARTS $REPORTS_ARTIFACTS_DIR $TESTS_DATA_DIR
        mkdir -p $TMP_DIR $OUT_DIR $ARTIFACTS_DIR $LOG_DIR $JUNIT_REPORT_PARTS $REPORTS_ARTIFACTS_DIR $TESTS_DATA_DIR
        chown -R github:github $TMP_DIR $OUT_DIR $ARTIFACTS_DIR $LOG_DIR $JUNIT_REPORT_PARTS \
                               $REPORTS_ARTIFACTS_DIR $SUMMARY_LINKS $GITHUB_WORKSPACE \
                               $GITHUB_STEP_SUMMARY $TESTS_DATA_DIR
        # shellcheck disable=SC2193
        if [ "${{ inputs.clean_ya_dir }}" == "yes" ] && [ -d /home/github/.ya/ ]; then
          echo "Cleaning ya dir"
          rm -rf /home/github/.ya/
        fi
        # checking /etc/hosts to see if vm was created correctly
        cat /etc/hosts

    - name: ya test
      shell: bash --noprofile --norc -eo pipefail -x {0}
      run: |
        set -x
        extra_params=()

        # shellcheck disable=SC2195
        case "${{ inputs.build_preset }}" in
          debug)
            build_type=debug
            ;;
          relwithdebinfo)
            build_type=relwithdebinfo
            ;;
          release-asan)
            build_type=release
            extra_params+=(--sanitize="address")
            extra_params+=(-DSKIP_JUNK -DUSE_EAT_MY_DATA -DDEBUGINFO_LINES_ONLY)
            ;;
          release-tsan)
            build_type=release
            extra_params+=(--sanitize="thread")
            extra_params+=(-DSKIP_JUNK -DUSE_EAT_MY_DATA -DDEBUGINFO_LINES_ONLY)
            ;;
          release-msan)
            build_type=release
            extra_params+=(--sanitize="memory")
            extra_params+=(-DSKIP_JUNK -DUSE_EAT_MY_DATA -DDEBUGINFO_LINES_ONLY)
            ;;
          release-ubsan)
            build_type=release
            extra_params+=(--sanitize="undefined")
            extra_params+=(-DSKIP_JUNK -DUSE_EAT_MY_DATA -DDEBUGINFO_LINES_ONLY)
            ;;
          *)
            echo "Invalid preset: ${{ inputs.build_preset }}"
            exit 1
            ;;
        esac

        # shellcheck disable=SC2157
        if [ -n "${{ inputs.test_target }}" ]; then
          readarray -d ',' -t targets < <(printf "%s" "${{ inputs.test_target }}")
          for target in "${targets[@]}"; do
            extra_params+=(--target="${target}")
          done
        fi

        # shellcheck disable=SC2193
        if [ "${{ inputs.use_network_cache }}" == "yes" ]; then
          # shellcheck disable=SC2157
          if [ -n "${{ inputs.bazel_remote_uri }}" ]; then
            extra_params+=(--bazel-remote-store)
            extra_params+=(--bazel-remote-base-uri "${{ inputs.bazel_remote_uri }}")
          fi

          # shellcheck disable=SC2157
          if [ -n "${{ inputs.bazel_remote_username }}" ]; then
            extra_params+=(--bazel-remote-username "${{ inputs.bazel_remote_username }}")
            extra_params+=(--bazel-remote-password "${{ inputs.bazel_remote_password }}")
          fi

          # shellcheck disable=SC2193
          if [ "${{ inputs.cache_update }}" = "true" ]; then
            extra_params+=(--bazel-remote-put)
          fi
        fi

        readarray -d ',' -t test_size < <(printf "%s" "${{ inputs.test_size }}")
        readarray -d ',' -t test_type < <(printf "%s" "${{ inputs.test_type }}")

        echo "::group::empty-files"
        [ -d  /home/github/.ya/tools/ ] && {
          find /home/github/.ya/tools/ -type f -exec file {} \; | grep empty;
          ya_bin_path=$(find /home/github/.ya/tools/ -type f -name "ya-bin")
          if [ ! -s "$ya_bin_path" ]; then
            echo "ya-bin exists but is empty, recovering by removing ya-bin"
            rm -rf $ya_bin_path
          fi
        }
        echo "::endgroup::"
        date
        echo "::group::ya-make-test"
        sudo -E -H -u github choom -n -1000 ./ya test -k --build "${build_type}" \
          "${test_size[@]/#/--test-size=}" "${test_type[@]/#/--test-type=}" \
          --test-threads "${{ inputs.test_threads }}" --link-threads "${{ inputs.link_threads }}" \
          --cache-size 512G --do-not-output-stderrs -T \
          --stat --log-file "$LOG_DIR/ya_log.txt" --evlog-file "$LOG_DIR/ya_evlog.jsonl" \
          --canonization-backend=ydb-canondata.storage.yandexcloud.net \
          --junit "$JUNIT_REPORT_XML" --output "$OUT_DIR" "${extra_params[@]}" || (
            RC=$?
            if [ $RC -ne 0 ]; then
              echo "ya test returned $RC, check existence $JUNIT_REPORT_XML"
              if [ -s "$JUNIT_REPORT_XML" ]; then
                echo "$JUNIT_REPORT_XML exists"
                ls -la "$JUNIT_REPORT_XML"
                echo "::endgroup::"
                date
              else
                echo "$JUNIT_REPORT_XML doesn't exist or has zero size"
                ls -la "$JUNIT_REPORT_XML" || true
                echo "::endgroup::"
                date
                exit $RC
              fi
            fi
        )

    - name: copying system files
      if: ${{ !cancelled() }}
      shell: bash --noprofile --norc -eo pipefail -x {0}
      run: |
        sudo cp /var/log/kern.log "$LOG_DIR/kern.log" &&
        sudo chown -R github:github "$LOG_DIR/kern.log" || true

    - name: archive unitest reports (orig)
      shell: bash --noprofile --norc -eo pipefail -x {0}
      run: |
        # shellcheck disable=SC2024
        sudo -E -H -u github gzip -c $JUNIT_REPORT_XML > $REPORTS_ARTIFACTS_DIR/orig_junit.xml.gz

    - name: postprocess junit report
      shell: bash --noprofile --norc -eo pipefail -x {0}
      run: |
        echo "::group::muted-tests"
        cat .github/config/muted_ya.txt
        cat .github/config/muted_ya_nebius.txt
        MUTED_CONFIG=".github/config/muted_ya.txt"
        # shellcheck disable=SC2193
        [ "${{ inputs.nebius }}" == "yes" ] && MUTED_CONFIG=".github/config/muted_ya_nebius.txt"
        echo "::endgroup::"
        echo "::group::postprocess-junit"
        sudo -E -H -u github .github/scripts/tests/transform-ya-junit.py -i \
          -m "${MUTED_CONFIG}" \
          --ya-out "$OUT_DIR" \
          --log-url-prefix "$S3_WEBSITE_PREFIX/logs/" \
          --data-url-prefix "$S3_WEBSITE_PREFIX/test_data$GITHUB_WORKSPACE" \
          --log-out-dir "$ARTIFACTS_DIR/logs/" \
          "$JUNIT_REPORT_XML"

        sudo -E -H -u github .github/scripts/tests/split-junit.py -o "$JUNIT_REPORT_PARTS" "$JUNIT_REPORT_XML"
        echo "::endgroup::"

    - name: dump VM artifacts
      shell: bash --noprofile --norc -eo pipefail -x {0}
      if: ${{ !cancelled() }}
      run: |
        echo "::group::dump-vm-artifacts"
        # shellcheck disable=SC2024
        sudo dmesg -T > "$LOG_DIR/dmesg.log" || true
        sudo cp /var/log/atop/atop_* "$LOG_DIR/" || true
        sudo cp /var/log/syslog "$LOG_DIR/syslog.log" || true
        sudo ps aux > "$LOG_DIR/ps.log" || true
        sudo chown -R github:github "$LOG_DIR/dmesg.log" "$LOG_DIR/atop_*" "$LOG_DIR/syslog.log" "$LOG_DIR/ps.log" || true
        echo "::endgroup::"

    - name: archive unitest reports (transformed)
      shell: bash --noprofile --norc -eo pipefail -x {0}
      run: |
        sudo -E -H -u github tar -C $JUNIT_REPORT_PARTS/.. -czf $REPORTS_ARTIFACTS_DIR/junit_parts.xml.tar.gz "$(basename $JUNIT_REPORT_PARTS)" $JUNIT_REPORT_XML

    - name: write tests summary
      shell: bash --noprofile --norc -eo pipefail -x {0}
      env:
        GITHUB_TOKEN: ${{ github.token }}
      run: |
        echo "::group::write-summary"
        sudo -E -H -u github mkdir $ARTIFACTS_DIR/summary/

        cat $SUMMARY_LINKS | python3 -c 'import sys; print(" | ".join([v for _, v in sorted([l.strip().split(" ", 1) for l in sys.stdin], key=lambda a: (int(a[0]), a))]))' >> $GITHUB_STEP_SUMMARY

        platform_name=$(uname | tr '[:upper:]' '[:lower:]')-$(arch)

        export SUMMARY_OUT_ENV_PATH=$(mktemp -p /home/github)
        chown github:github $SUMMARY_OUT_ENV_PATH
        sudo -E -H -u github .github/scripts/tests/generate-summary.py \
          --summary-out-path "$ARTIFACTS_DIR/summary/" \
          --summary-out-env-path "$SUMMARY_OUT_ENV_PATH" \
          --summary-url-prefix "$S3_WEBSITE_PREFIX/summary/" \
          --build-preset "${platform_name}-${{ inputs.build_preset }}" \
          "Tests" ya-test.html "$JUNIT_REPORT_XML"

        cat $SUMMARY_OUT_ENV_PATH | tee -a $GITHUB_STEP_SUMMARY
        echo "::endgroup::"

    - name: check test results
      shell: bash --noprofile --norc -eo pipefail -x {0}
      run: |
        sudo -E -H -u github .github/scripts/tests/fail-checker.py "$JUNIT_REPORT_XML" || {
          RC=$?

          echo "::group::Copy-failed-tests-data"
          sudo -E -H -u github .github/scripts/tests/fail-checker.py "$JUNIT_REPORT_XML" --paths-only
          sudo -E -H -u github .github/scripts/tests/fail-checker.py "$JUNIT_REPORT_XML" --paths-only | while read -r path; do
            echo $path
            find "${GITHUB_WORKSPACE}/${path}" -print0 | xargs -0 xargs -0 cp -L -r --parents -t "$TESTS_DATA_DIR"
          done
          chown -R github:github "$TESTS_DATA_DIR"
          echo "::endgroup::"
          echo "::group::remove-binaries-from-tests-data-dir"
          find "$TESTS_DATA_DIR" -type f -print0 | xargs -0 -n 10 file -i  | grep "application/x-executable" | awk -F: '{print $1}'
          find "$TESTS_DATA_DIR" -type f -print0 | xargs -0 -n 10 file -i  | grep "application/x-executable" | awk -F: '{print $1}' | xargs rm
          echo "::endgroup::"
          echo "::group::remove-images-from-tests-data-dir"
          find "$TESTS_DATA_DIR" -name generated_raw_image -o -name generated_vmdk_image -o -name invalid_qcow2_image -o -name qcow2_fuzzing_image -o -name NVMENBS01 -o -name generated_other_big_raw_image
          find "$TESTS_DATA_DIR" \( -name generated_raw_image -o -name generated_vmdk_image -o -name invalid_qcow2_image -o -name qcow2_fuzzing_image -o -name NVMENBS01 -o -name generated_other_big_raw_image \) -delete
          echo "::endgroup::"
          echo "::group::truncate-err-files"
          find "$TESTS_DATA_DIR" -type f -name "*.err" -size +1G -print0 | while IFS= read -r -d '' file; do
              orig_size=$(du -h "$file" | cut -f1)
              echo "$file - $orig_size"
              # shellcheck disable=SC2193
              if [ "${{ inputs.truncate_enabled }}" == "yes" ]; then
                truncate -s 1G "$file"
                echo "... truncated (original size was $orig_size) ..." >> "$file"
              else
                echo "not truncated"
              fi
          done
          echo "::endgroup::"
          echo "::group::s3-sync"
          if [ "$SYNC_TO_S3" = "true" ];
          then
            du -h "$TESTS_DATA_DIR/"
            sudo -E -H -u github s3cmd sync --follow-symlinks --acl-private --no-progress --stats --no-check-md5 "$TESTS_DATA_DIR/" "$S3_BUCKET_PATH/test_data/"
          fi
          echo "::endgroup::"
          exit $RC
        }
      env:
        SYNC_TO_S3: ${{ inputs.sync_to_s3 || 'false' }}

    - name: Sync test results to S3
      if: always()
      shell: bash
      run: |
        echo "::group::s3-sync"
        sudo -E -H -u github s3cmd sync --follow-symlinks --acl-public --no-progress --stats --no-check-md5 "$ARTIFACTS_DIR/" "$S3_BUCKET_PATH/"
        echo "::endgroup::"

    - name: Sync logs results to S3
      if: always()
      shell: bash
      run: |
        echo "::group::s3-sync"
        sudo -E -H -u github s3cmd sync --follow-symlinks --acl-private --no-progress --stats --no-check-md5 "$LOG_DIR/" "$S3_BUCKET_PATH/test_logs/"
        echo "::endgroup::"
    - name: Sync reports to S3
      if: always()
      shell: bash
      run: |
        echo "::group::s3-sync"
        sudo -E -H -u github s3cmd sync --follow-symlinks --acl-private --no-progress --stats --no-check-md5 "$LOG_DIR/" "$S3_BUCKET_PATH/test_logs/"
        echo "::endgroup::"

    - name: Display links to s3 summary
      if: always()
      shell: bash
      run: |
        echo "::group::s3-report-links"
        echo ${S3_URL_PREFIX}/summary/ya-test.html
        echo ${S3_WEBSITE_PREFIX}/summary/ya-test.html
        echo "::endgroup::"

    - name: upload ya dir to s3 on success
      id: upload_ya_dir
      shell: bash --noprofile --norc -eo pipefail -x {0}
      if: success() && inputs.upload_ya_dir == 'yes'
      run: |
        function grep_ya_tc() {
          ps aux | grep "[y]a-tc" || true
        }
        process_name="ya-tc"
        # by default ya-tc should terminate within 5 minutes
        timeout=360
        start_time=$(date +%s)
        while true; do
            pgrep -x "$process_name" && {
                echo "$process_name is still running."
                grep_ya_tc
            } || {
                echo "$process_name is not running."
                grep_ya_tc
                break
            }

            current_time=$(date +%s)
            elapsed_time=$((current_time - start_time))

            if [ "$elapsed_time" -ge "$timeout" ]; then
                echo "Timeout reached. $process_name is still running. killing it"
                grep_ya_tc
                pkill -f $process_name || true
                grep_ya_tc
                break
            fi

            sleep 5
        done

        ps aux | grep ya
        # checking if files are not corrupted
        echo "::group::ya-files-empty"
        find /home/github/.ya/tools/ -type f -exec file {} \; | grep empty
        echo "::endgroup::"
        ya_bin_path=$(find /home/github/.ya/tools/ -type f -name "ya-bin")
        if [ ! -s "$ya_bin_path" ]; then
          echo "ya-bin exists but is empty"
          echo "empty_ya_bin=yes" >> $GITHUB_OUTPUT
        else
          echo "empty_ya_bin=no" >> $GITHUB_OUTPUT
          echo "::group::upload-ya-dir"

          df -h
          EXTENSION=tar.xz
          if [ "$EXTENSION" = "tar.zst" ] || [ "$EXTENSION" = "tar.zstd" ]; then COMPRESS_ARGS='zstd -16 -T60'; fi
          if [ "$EXTENSION" = "tar.xz" ]; then COMPRESS_ARGS='pixz -1'; fi
          if [ "$EXTENSION" = "tar.bz2" ]; then COMPRESS_ARGS=pbzip2; fi
          if [ "$EXTENSION" = "tar.gz" ]; then COMPRESS_ARGS=pigz; fi
          sudo -E -H -u github time tar -S -C /home/github -I "$COMPRESS_ARGS" -c -f  /home/github/tmp/ya.${EXTENSION} /home/github/.ya
          ls -lsha /home/github/tmp/ya.${EXTENSION}
          sudo -E -H -u github time aws s3 cp --no-progress  /home/github/tmp/ya.${EXTENSION} "$S3_BUCKET_PATH/ya_archive/ya.${EXTENSION}"
          echo "${S3_WEBSITE_PREFIX}/ya_archive/ya.${EXTENSION}" > /home/github/ya_web_url.txt
          echo "${S3_BUCKET_PATH}/ya_archive/ya.${EXTENSION}" > /home/github/ya_s3_url.txt
          df -h
          echo "::endgroup::"
        fi

    - name: upload ya url to s3 on success
      if: success() && inputs.upload_ya_dir == 'yes' && steps.upload_ya_dir.outputs.empty_ya_bin != 'yes'
      uses: actions/upload-artifact@v4
      with:
        name: ya_web_url_file
        path: /home/github/ya_web_url.txt
    - name: upload ya url to s3 on success
      if: success() && inputs.upload_ya_dir == 'yes' && steps.upload_ya_dir.outputs.empty_ya_bin != 'yes'
      uses: actions/upload-artifact@v4
      with:
        name: ya_s3_url_file
        path: /home/github/ya_s3_url.txt
    - name: Create directory listing on s3
      if: always()
      shell: bash
      run: |
        echo "::group::generate-listing"
        sudo -E -H -u github python3 .github/scripts/index.py "$S3_BUCKET_PATH" --generate-indexes --apply
        echo "::endgroup::"
    - name: show free space
      if: always()
      shell: bash
      run: df -h
